#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì£¼ì‹ ë°ì´í„° í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸
ë§¤ì¼ ìƒˆë²½ 1ì‹œì— ì‹¤í–‰ë˜ì–´ ì£¼ì‹ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  JSON íŒŒì¼ë¡œ ì €ì¥
"""

import requests
import json
import time
import logging
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import random
import os

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì • - GitHub Actions í™˜ê²½ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì„¤ì •"""
    if os.environ.get('GITHUB_ACTIONS', 'false').lower() == 'true':
        # GitHub Actionsì—ì„œëŠ” ì½˜ì†” ì¶œë ¥ë§Œ
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler()
            ]
        )
    else:
        # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” íŒŒì¼ê³¼ ì½˜ì†” ëª¨ë‘
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('crawler.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

# ë¡œê¹… ì„¤ì • ì‹¤í–‰
setup_logging()

class StockDataCrawler:
    def __init__(self):
        self.base_url = "https://finance.naver.com"
        # GitHub Actions í™˜ê²½ì—ì„œëŠ” í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
        self.data_dir = os.environ.get('DATA_DIR', 'data' if os.path.exists("data") else "../data")
        self.ensure_data_directory()
        
        # GitHub Actions í™˜ê²½ ê°ì§€
        self.is_github_actions = os.environ.get('GITHUB_ACTIONS', 'false').lower() == 'true'
        
        # ì£¼ìš” ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (KOSPI, KOSDAQ)
        self.stock_list = [
            {"code": "005930", "name": "ì‚¼ì„±ì „ì", "market": "KOSPI"},
            {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤", "market": "KOSPI"},
            {"code": "035420", "name": "NAVER", "market": "KOSPI"},
            {"code": "051910", "name": "LGí™”í•™", "market": "KOSPI"},
            {"code": "006400", "name": "ì‚¼ì„±SDI", "market": "KOSPI"},
            {"code": "207940", "name": "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤", "market": "KOSPI"},
            {"code": "068270", "name": "ì…€íŠ¸ë¦¬ì˜¨", "market": "KOSPI"},
            {"code": "323410", "name": "ì¹´ì¹´ì˜¤ë±…í¬", "market": "KOSPI"},
            {"code": "035720", "name": "ì¹´ì¹´ì˜¤", "market": "KOSPI"},
            {"code": "086790", "name": "í•˜ë‚˜ê¸ˆìœµì§€ì£¼", "market": "KOSPI"},
            {"code": "105560", "name": "KBê¸ˆìœµ", "market": "KOSPI"},
            {"code": "055550", "name": "ì‹ í•œì§€ì£¼", "market": "KOSPI"},
            {"code": "139480", "name": "ì´ë§ˆíŠ¸", "market": "KOSPI"},
            {"code": "028260", "name": "ì‚¼ì„±ë¬¼ì‚°", "market": "KOSPI"},
            {"code": "017670", "name": "SKí…”ë ˆì½¤", "market": "KOSPI"},
            {"code": "015760", "name": "í•œêµ­ì „ë ¥", "market": "KOSPI"},
            {"code": "010950", "name": "S-Oil", "market": "KOSPI"},
            {"code": "096770", "name": "SKì´ë…¸ë² ì´ì…˜", "market": "KOSPI"},
            {"code": "034020", "name": "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°", "market": "KOSPI"},
            {"code": "373220", "name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜", "market": "KOSPI"}
        ]
        
        # í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ë°©ì§€)
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
    
    def ensure_data_directory(self):
        """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            logging.info(f"ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±: {self.data_dir}")
    
    def get_stock_price(self, stock_code):
        """ê°œë³„ ì¢…ëª©ì˜ í˜„ì¬ê°€ ì •ë³´ ìˆ˜ì§‘"""
        try:
            url = f"{self.base_url}/item/main.naver?code={stock_code}"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # í˜„ì¬ê°€ ì¶”ì¶œ
            price_element = soup.select_one('div.today p.no_today span.blind')
            if price_element:
                current_price = price_element.get_text(strip=True).replace(',', '')
                current_price = int(current_price) if current_price.isdigit() else 0
            else:
                current_price = 0
            
            # ì „ì¼ ëŒ€ë¹„ ë³€ë™ ì¶”ì¶œ
            change_element = soup.select_one('div.today p.no_exday em span.blind')
            if change_element:
                change_text = change_element.get_text(strip=True)
                change_amount = 0
                change_percent = 0
                
                if 'ìƒìŠ¹' in change_text or 'í•˜ë½' in change_text:
                    # ë³€ë™ê¸ˆì•¡ê³¼ ë³€ë™ë¥  ì¶”ì¶œ
                    amount_element = soup.select_one('div.today p.no_exday em span.blind + span')
                    if amount_element:
                        amount_text = amount_element.get_text(strip=True)
                        change_amount = int(amount_text.replace(',', '').replace('+', '').replace('-', ''))
                        
                        # ë³€ë™ë¥  ì¶”ì¶œ
                        percent_element = soup.select_one('div.today p.no_exday em span.blind + span + span')
                        if percent_element:
                            percent_text = percent_element.get_text(strip=True)
                            change_percent = float(percent_text.replace('%', '').replace('+', '').replace('-', ''))
            else:
                change_amount = 0
                change_percent = 0
            
            # ê±°ë˜ëŸ‰ ì¶”ì¶œ
            volume_element = soup.select_one('table.type5 tr:nth-child(2) td:nth-child(3)')
            if volume_element:
                volume_text = volume_element.get_text(strip=True).replace(',', '')
                volume = int(volume_text) if volume_text.isdigit() else 0
            else:
                volume = 0
            
            # ì‹œê°€ì´ì•¡ ì¶”ì¶œ
            market_cap_element = soup.select_one('table.type5 tr:nth-child(1) td:nth-child(2)')
            if market_cap_element:
                market_cap_text = market_cap_element.get_text(strip=True).replace(',', '').replace('ì–µì›', '')
                market_cap = float(market_cap_text) if market_cap_text.replace('.', '').isdigit() else 0
            else:
                market_cap = 0
            
            return {
                "code": stock_code,
                "current_price": current_price,
                "change_amount": change_amount,
                "change_percent": change_percent,
                "volume": volume,
                "market_cap": market_cap,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logging.error(f"ì¢…ëª© {stock_code} ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_market_indices(self):
        """ì£¼ìš” ì§€ìˆ˜ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # KOSPI
            kospi_url = "https://finance.naver.com/sise/sise_index.nhn?code=KOSPI"
            response = requests.get(kospi_url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # KOSPI í˜„ì¬ê°’
            kospi_element = soup.select_one('div.head_area span.value')
            kospi_value = 0
            if kospi_element:
                kospi_text = kospi_element.get_text(strip=True).replace(',', '')
                kospi_value = float(kospi_text) if kospi_text.replace('.', '').isdigit() else 0
            
            # KOSPI ë³€ë™
            kospi_change_element = soup.select_one('div.head_area span.change')
            kospi_change = 0
            if kospi_change_element:
                kospi_text = kospi_change_element.get_text(strip=True).replace(',', '').replace('+', '').replace('-', '')
                kospi_change = float(kospi_text) if kospi_text.replace('.', '').isdigit() else 0
            
            # KOSDAQ
            kosdaq_url = "https://finance.naver.com/sise/sise_index.nhn?code=KOSDAQ"
            response = requests.get(kosdaq_url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # KOSDAQ í˜„ì¬ê°’
            kosdaq_element = soup.select_one('div.head_area span.value')
            kosdaq_value = 0
            if kosdaq_element:
                kosdaq_text = kosdaq_element.get_text(strip=True).replace(',', '')
                kosdaq_value = float(kosdaq_text) if kosdaq_text.replace('.', '').isdigit() else 0
            
            # KOSDAQ ë³€ë™
            kosdaq_change_element = soup.select_one('div.head_area span.change')
            kosdaq_change = 0
            if kosdaq_change_element:
                kosdaq_text = kosdaq_change_element.get_text(strip=True).replace(',', '').replace('+', '').replace('-', '')
                kosdaq_change = float(kosdaq_text) if kosdaq_text.replace('.', '').isdigit() else 0
            
            return {
                "kospi": {
                    "value": kospi_value,
                    "change": kospi_change,
                    "timestamp": datetime.now().isoformat()
                },
                "kosdaq": {
                    "value": kosdaq_value,
                    "change": kosdaq_change,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
        except Exception as e:
            logging.error(f"ì§€ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_economic_news(self):
        """ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            # ë„¤ì´ë²„ ê²½ì œ ë‰´ìŠ¤
            news_url = "https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1=101"
            response = requests.get(news_url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            news_list = []
            news_elements = soup.select('div.cluster_group div.cluster_text_headline a')
            
            for i, news in enumerate(news_elements[:10]):  # ìƒìœ„ 10ê°œ ë‰´ìŠ¤
                title = news.get_text(strip=True)
                link = "https://news.naver.com" + news.get('href', '')
                
                news_list.append({
                    "title": title,
                    "link": link,
                    "timestamp": datetime.now().isoformat()
                })
            
            return news_list
            
        except Exception as e:
            logging.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def generate_historical_data(self, stock_code, days=30):
        """ê³¼ê±° ë°ì´í„° ìƒì„± (ì‹¤ì œ APIê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜)"""
        try:
            # í˜„ì¬ê°€ ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° ë°ì´í„° ìƒì„±
            current_data = self.get_stock_price(stock_code)
            if not current_data:
                return []
            
            current_price = current_data['current_price']
            historical_data = []
            
            for i in range(days, 0, -1):
                date = datetime.now() - timedelta(days=i)
                
                # ê°€ê²© ë³€ë™ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
                variation = random.uniform(-0.05, 0.05)  # Â±5% ë³€ë™
                price = int(current_price * (1 + variation))
                
                historical_data.append({
                    "date": date.strftime("%Y-%m-%d"),
                    "price": price,
                    "volume": random.randint(1000000, 10000000)
                })
            
            return historical_data
            
        except Exception as e:
            logging.error(f"ê³¼ê±° ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return []
    
    def crawl_all_data(self):
        """ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥"""
        logging.info("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        start_time = time.time()
        
        try:
            # 1. ì£¼ì‹ ê°œë³„ ì •ë³´ ìˆ˜ì§‘
            logging.info("ğŸ“ˆ ì£¼ì‹ ê°œë³„ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
            stock_data = []
            for i, stock in enumerate(self.stock_list, 1):
                logging.info(f"[{i}/{len(self.stock_list)}] ì¢…ëª© ì •ë³´ ìˆ˜ì§‘ ì¤‘: {stock['name']} ({stock['code']})")
                stock_info = self.get_stock_price(stock['code'])
                if stock_info:
                    stock_info.update(stock)
                    stock_data.append(stock_info)
                    logging.info(f"   âœ… {stock['name']}: {stock_info['current_price']:,}ì› ({stock_info['change_percent']:+.2f}%)")
                else:
                    logging.warning(f"   âŒ {stock['name']}: ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                time.sleep(random.uniform(1, 3))
            
            # 2. ì‹œì¥ ì§€ìˆ˜ ìˆ˜ì§‘
            logging.info("ğŸ“Š ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
            market_indices = self.get_market_indices()
            if market_indices:
                logging.info(f"   âœ… KOSPI: {market_indices['kospi']['value']:,.2f} ({market_indices['kospi']['change']:+.2f})")
                logging.info(f"   âœ… KOSDAQ: {market_indices['kosdaq']['value']:,.2f} ({market_indices['kosdaq']['change']:+.2f})")
            else:
                logging.warning("   âŒ ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨")
            
            # 3. ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘
            logging.info("ğŸ“° ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            economic_news = self.get_economic_news()
            logging.info(f"   âœ… ë‰´ìŠ¤ {len(economic_news)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # 4. ê³¼ê±° ë°ì´í„° ìƒì„± (ì‹¤ì œë¡œëŠ” APIì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
            logging.info("ğŸ“… ê³¼ê±° ë°ì´í„° ìƒì„± ì¤‘...")
            historical_data = {}
            for stock in stock_data[:5]:  # ìƒìœ„ 5ê°œ ì¢…ëª©ë§Œ
                logging.info(f"   ğŸ“Š {stock['name']} ê³¼ê±° ë°ì´í„° ìƒì„± ì¤‘...")
                historical_data[stock['code']] = self.generate_historical_data(stock['code'])
            
            # 5. ë°ì´í„° í†µí•© ë° ì €ì¥
            logging.info("ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
            all_data = {
                "timestamp": datetime.now().isoformat(),
                "stocks": stock_data,
                "market_indices": market_indices,
                "news": economic_news,
                "historical_data": historical_data
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            data_file = os.path.join(self.data_dir, f"stock_data_{datetime.now().strftime('%Y%m%d')}.json")
            with open(data_file, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            logging.info(f"   ğŸ“ ì¼ì¼ ë°ì´í„° ì €ì¥: {data_file}")
            
            # ìµœì‹  ë°ì´í„° íŒŒì¼ë„ ìƒì„±
            latest_file = os.path.join(self.data_dir, "latest_stock_data.json")
            with open(latest_file, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=2)
            logging.info(f"   ğŸ“ ìµœì‹  ë°ì´í„° ì €ì¥: {latest_file}")
            
            end_time = time.time()
            logging.info(f"ğŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            logging.info(f"   ğŸ“Š ì´ {len(stock_data)}ê°œ ì¢…ëª©")
            logging.info(f"   ğŸ“° ë‰´ìŠ¤ {len(economic_news)}ê±´")
            logging.info(f"   â±ï¸ ì†Œìš”ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
            
            return True
            
        except Exception as e:
            logging.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logging.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def cleanup_old_data(self, days_to_keep=7):
        """ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì •ë¦¬"""
        try:
            current_time = datetime.now()
            data_files = [f for f in os.listdir(self.data_dir) if f.startswith('stock_data_') and f.endswith('.json')]
            
            for file_name in data_files:
                file_path = os.path.join(self.data_dir, file_name)
                file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                
                if (current_time - file_time).days > days_to_keep:
                    os.remove(file_path)
                    logging.info(f"ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì‚­ì œ: {file_name}")
            
        except Exception as e:
            logging.error(f"ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = StockDataCrawler()
    
    try:
        # ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        success = crawler.crawl_all_data()
        
        if success:
            # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
            crawler.cleanup_old_data()
            logging.info("ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ì™„ë£Œ")
        else:
            logging.error("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            
    except Exception as e:
        logging.error(f"í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    main()
